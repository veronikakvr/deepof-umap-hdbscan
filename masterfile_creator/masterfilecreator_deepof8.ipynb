{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddfd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 CSV files in /Users/veronika/ownCloud/PCA_analysis2025/SocialOF/HFD/males/atg7KO/Single/rawdata\n"
     ]
    }
   ],
   "source": [
    "# Set your specific directory here\n",
    "csv_dir = r'/Users/veronika/ownCloud/PCA_analysis2025/SocialOF/HFD/males/atg7KO/Single/rawdata' #load your raw deepof 0.8 csv data from a specific directory\n",
    "file_list = glob.glob(f'{csv_dir}/*.csv')\n",
    "output_path = r'/Users/veronika/ownCloud/PCA_analysis2025/SocialOF/HFD/males/atg7KO/Single' # Path to save the merged CSV file\n",
    "\n",
    "print(f\"Found {len(file_list)} CSV files in {csv_dir}\") # this will print the number of CSV files found in the first specified directory - check if the files are loaded correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f30995",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Merge all CSV files into a single DataFrame and renames the first column to \"Time\" and adds an \"experimental_id\" column with the file name (without extension)\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    # Rename the first column to \"Time\"\n",
    "    if len(df.columns) > 0:\n",
    "        df.rename(columns={df.columns[0]: \"Time\"}, inplace=True)\n",
    "    # Add experimental_id column with file name (without extension)\n",
    "    df['experimental_id'] = file.split('/')[-1].split('.')[0]\n",
    "    dfs.append(df)\n",
    "\n",
    "master_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa30d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset saved to: /Users/veronika/ownCloud/PCA_analysis2025/SocialOF/HFD/males/atg7KO/Single/master_combined_males_atg7KO_HFD_Single.csv\n"
     ]
    }
   ],
   "source": [
    "out_file = os.path.join(output_path, 'master_combined_males_atg7KO_HFD_Single.csv') # Save the merged DataFrame to a CSV file\n",
    "master_df.to_csv(out_file, index=False)\n",
    "print(f\"✅ Dataset saved to: {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Set your directory and condition file paths\n",
    "csv_file = Path(r'/Users/veronika/ownCloud/PCA_analysis2025/SocialOF/HFD/males/atg7KO/Single/master_combined_males_atg7KO_HFD_Single.csv') #this is the path to the merged CSV file, we created above\n",
    "condition_file = Path(r'/Users/veronika/ownCloud/PCA_analysis2025/SocialOF/HFD/males/atg7KO/exp_condi_atg7KOmales_HFD.csv') #this is the path to the condition file, which contains the experimental conditions for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "225f49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load condition mapping file\n",
    "condition_df = pd.read_csv(condition_file)\n",
    "\n",
    "# Create genotype map based on experimental ID\n",
    "geno_map = dict(zip(condition_df['experimental_id'], condition_df['Geno']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62aac327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data file\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename first column to \"Time\" if necessary - this is to ensure consistency\n",
    "if df.columns[0] != 'Time':\n",
    "    df.rename(columns={df.columns[0]: 'Time'}, inplace=True)\n",
    "\n",
    "# Extract just the ID (e.g., \"ID196\") from the 'experimental_id' path\n",
    "df['experimental_id'] = df['experimental_id'].apply(lambda x: Path(x).name.split('+')[0])\n",
    "\n",
    "# Map to Geno\n",
    "df['Geno'] = df['experimental_id'].map(geno_map).fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5090aab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved cleaned file to: /Users/veronika/ownCloud/PCA_analysis2025/SocialOF/HFD/males/atg7KO/Single/master_combined_males_atg7KO_HFD_Single_FINAL.csv\n"
     ]
    }
   ],
   "source": [
    "# Save final output\n",
    "output_file = csv_file.parent / (csv_file.stem + '_FINAL.csv')\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Saved cleaned file to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4421e8d",
   "metadata": {},
   "source": [
    "##  A little code check if experimental conditions were loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7e97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique genotypes found: ['control' 'atg7KO']\n"
     ]
    }
   ],
   "source": [
    "#This will print the unique genotypes found in the dataset - useful for debugging\n",
    "unique_genotypes = df['Geno'].unique()\n",
    "print(f\"Unique genotypes found: {unique_genotypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1405a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknown genotypes: 0\n"
     ]
    }
   ],
   "source": [
    "# Another check to see if there are any unknown genotypes (should have been filled with 'Unknown' and already checked above)\n",
    "geno_check = df[df[\"Geno\"] == \"Unknown\"]\n",
    "print(f\"Number of unknown genotypes: {len(geno_check)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e665b1",
   "metadata": {},
   "source": [
    "#   Proceed only if you have anytroubles with geno matching or time in your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babfd91f",
   "metadata": {},
   "source": [
    "Checking for the Unknown genotype and to what experimental ID it matches - if there are inconsisencies in loading, check if the experimental file at the beginning is formatted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7aa6843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataframe for rows where genotype is 'Unknown'\n",
    "unknown_geno_df = df[df['Geno'] == 'Unknown']\n",
    "\n",
    "# List all unique experimental_id values with Unknown genotype\n",
    "experimental_ids_with_unknown = unknown_geno_df['experimental_id'].unique()\n",
    "\n",
    "print(experimental_ids_with_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d9b501",
   "metadata": {},
   "source": [
    "Checking if the Time corresponds to a lenght we would expect - e.g. no funny timestamps - it should look like e.g.: '00:00:00' ... '00:09:59.0665'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78912ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique time points found: ['00:00:00' '00:00:00.066563296' '00:00:00.066566754' ...\n",
      " '00:10:01.866828890' '00:10:01.933348095' '00:10:01.933414445']\n"
     ]
    }
   ],
   "source": [
    "unique_Times = df.sort_values(['Time', 'experimental_id']).reset_index(drop=True)\n",
    "unique_Times = unique_Times['Time'].unique()\n",
    "print(f\"Unique time points found: {unique_Times}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f83a78",
   "metadata": {},
   "source": [
    "Checking the whole dataset as a table - if the behaviours look right, experimental id make sense and the mapping to Geno looks ok - check the Time column here!! Excel can be funny and additional forcing to the right format might be neccessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fac74ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>climb-arena</th>\n",
       "      <th>sniff-arena</th>\n",
       "      <th>immobility</th>\n",
       "      <th>stat-lookaround</th>\n",
       "      <th>stat-active</th>\n",
       "      <th>stat-passive</th>\n",
       "      <th>moving</th>\n",
       "      <th>sniffing</th>\n",
       "      <th>speed</th>\n",
       "      <th>missing</th>\n",
       "      <th>experimental_id</th>\n",
       "      <th>Geno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187582</th>\n",
       "      <td>00:10:00.667036011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.595</td>\n",
       "      <td>0</td>\n",
       "      <td>ID95</td>\n",
       "      <td>atg7KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187583</th>\n",
       "      <td>00:10:00.733628808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.490</td>\n",
       "      <td>0</td>\n",
       "      <td>ID95</td>\n",
       "      <td>atg7KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187584</th>\n",
       "      <td>00:10:00.800221606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.690</td>\n",
       "      <td>0</td>\n",
       "      <td>ID95</td>\n",
       "      <td>atg7KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187585</th>\n",
       "      <td>00:10:00.866814404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.660</td>\n",
       "      <td>0</td>\n",
       "      <td>ID95</td>\n",
       "      <td>atg7KO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187586</th>\n",
       "      <td>00:10:00.933407202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.830</td>\n",
       "      <td>0</td>\n",
       "      <td>ID95</td>\n",
       "      <td>atg7KO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time  climb-arena  sniff-arena  immobility  \\\n",
       "187582  00:10:00.667036011          0.0          0.0         0.0   \n",
       "187583  00:10:00.733628808          0.0          0.0         0.0   \n",
       "187584  00:10:00.800221606          0.0          0.0         0.0   \n",
       "187585  00:10:00.866814404          0.0          0.0         0.0   \n",
       "187586  00:10:00.933407202          0.0          0.0         0.0   \n",
       "\n",
       "        stat-lookaround  stat-active  stat-passive  moving  sniffing   speed  \\\n",
       "187582              0.0          0.0           0.0     1.0       0.0  53.595   \n",
       "187583              0.0          0.0           0.0     1.0       0.0  47.490   \n",
       "187584              0.0          0.0           0.0     1.0       1.0  39.690   \n",
       "187585              0.0          0.0           0.0     1.0       0.0  27.660   \n",
       "187586              0.0          0.0           0.0     1.0       0.0  13.830   \n",
       "\n",
       "        missing experimental_id    Geno  \n",
       "187582        0            ID95  atg7KO  \n",
       "187583        0            ID95  atg7KO  \n",
       "187584        0            ID95  atg7KO  \n",
       "187585        0            ID95  atg7KO  \n",
       "187586        0            ID95  atg7KO  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted = df.sort_values(by=['experimental_id', 'Time']).reset_index(drop=True)\n",
    "df_sorted.tail()  # Display the first few rows of the sorted DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
